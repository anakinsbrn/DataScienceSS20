{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "6_b_AutoSkLearn_Regression_NY_Taxy.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFneECLoTYLx",
        "colab_type": "text"
      },
      "source": [
        "# Block 6 Exercise 2: finding the best parameters for predicting the fare of taxi rides\n",
        "We return to our Random Forest Regression and want to automatically optimize all free parameters ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vzwBjLsTYLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import folium\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNcFrHWgTYL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "84d32aba-cde1-4976-a2b2-f445f944a2e5"
      },
      "source": [
        "#check if notebook runs in colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "print('running in Colab:',IN_COLAB)\n",
        "path='..'\n",
        "if IN_COLAB:\n",
        "  #in colab, we need to clone the data from the repo\n",
        "  !git clone https://github.com/keuperj/DataScienceSS20.git\n",
        "  path='DataScienceSS20'"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running in Colab: True\n",
            "fatal: destination path 'DataScienceSS20' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_M_9D0TYL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we load the data we have saved after wrangling and pre-processing in block I\n",
        "X=pd.read_csv(path+'/DATA/train_cleaned.csv')\n",
        "drop_columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','key','pickup_datetime','pickup_date','pickup_latitude_round3','pickup_longitude_round3','dropoff_latitude_round3','dropoff_longitude_round3']\n",
        "X=X.drop(drop_columns,axis=1)\n",
        "X=pd.get_dummies(X)# one hot coding\n",
        "#generate labels\n",
        "y=X['fare_amount']\n",
        "X=X.drop(['fare_amount'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3f91eWeTYL9",
        "colab_type": "text"
      },
      "source": [
        "### Scikit Optimize\n",
        "Scikit Optimize (https://scikit-optimize.github.io/stable/index.html) is a AutoML toolbox wrapped around Scikit-Learn. It allows us to use state-of-the-art automatic hyper-parameter optimization on top of our learning algorithms.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lBQWYPTYL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e568765d-7625-4dcd-da53-62ef0f1fd121"
      },
      "source": [
        "# install \n",
        "!pip install scikit-optimize"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.15.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (20.4.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUcF_MHTYMA",
        "colab_type": "text"
      },
      "source": [
        "### E 2.1 Bayesian Optimization of a Random Forest Regression Model\n",
        "use Bayesian Optimization with Cross-Validation (https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV) to find the best regression model. Compare\n",
        "* linear regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) \n",
        "* Random Forest regression (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
        "* and SVM regression (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)\n",
        "\n",
        "NOTES: this can become quite compute intensive! Hence,\n",
        "* use a smaller subset of the training data to run the experiments \n",
        "* think about the range of your parameters (e.g. larger number of trees in RF or high C-values in SMV will make models expensive)\n",
        "* optimize only the following parameters per model type:\n",
        "    * linear: no parameters to optimize\n",
        "    * RF: #trees and depth\n",
        "    * SVM: C and gamma (use RBF kernel)\n",
        "* parallelize -> n_jobs\n",
        "* use CoLab to rum the job for up to 12h \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4nDpolATYMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BSvjMaZUOOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simple model only using Random Forest\n",
        "\n",
        "X, y = load_iris(True)\n",
        "X= np.array(X)\n",
        "y= np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.75,random_state=0)\n",
        "\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)\n"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NimB5eZKpi_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "790ddb38-7f32-4906-f8b3-f92263c88cb7"
      },
      "source": [
        "opt = BayesSearchCV(\n",
        "    SVC(),\n",
        "    {\n",
        "        'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "        'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "        'degree': Integer(1,8),\n",
        "        'kernel': Categorical(['linear', 'poly', 'rbf']),\n",
        "     },\n",
        "     n_iter=32,\n",
        "     random_state=0\n",
        "     )\n",
        "\n",
        "opt.fit(X_train,y_train)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BayesSearchCV(cv=None, error_score='raise',\n",
              "              estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                            class_weight=None, coef0=0.0,\n",
              "                            decision_function_shape='ovr', degree=3,\n",
              "                            gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                            probability=False, random_state=None,\n",
              "                            shrinking=True, tol=0.001, verbose=False),\n",
              "              fit_params=None, iid=True, n_iter=32, n_jobs=1, n_points=1,\n",
              "              optimizer_kwargs=No...\n",
              "              refit=True, return_train_score=False, scoring=None,\n",
              "              search_spaces={'C': Real(low=1e-06, high=1000000.0, prior='log-uniform', transform='identity'),\n",
              "                             'degree': Integer(low=1, high=8, prior='uniform', transform='identity'),\n",
              "                             'gamma': Real(low=1e-06, high=10.0, prior='log-uniform', transform='identity'),\n",
              "                             'kernel': Categorical(categories=('linear', 'poly', 'rbf'), prior=None)},\n",
              "              verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39hxisUWYTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a43cd887-fa43-41ba-f4f5-7b2d0520584c"
      },
      "source": [
        "opt.best_score_"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9821428571428571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmByQeAcW6-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fb9f5996-f425-4f3a-fc5d-8118fb288c73"
      },
      "source": [
        "opt.best_params_"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('C', 1.3361910455737007),\n",
              "             ('degree', 5),\n",
              "             ('gamma', 0.11283439533114079),\n",
              "             ('kernel', 'linear')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du0UCbtkeRr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([\n",
        "    ('model', SVR()) #just put one model as placeholder\n",
        "])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8k2elAX52d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_regr = {\n",
        "  'model': Categorical([LinearRegression()]),\n",
        "}\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZVDa5s5ZIBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest Regression\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "#X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
        "rf_regr = {\n",
        "    'model': Categorical([RandomForestRegressor()]),\n",
        "    'model__n_estimators': Integer(10, 100, 'log-uniform'),\n",
        "}"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgd5oPaHZyqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM Regression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "n_samples, n_features = 10, 5\n",
        "rng = np.random.RandomState(0)\n",
        "y_train = rng.randn(n_samples)\n",
        "X_train = rng.randn(n_samples, n_features)\n",
        "svm_regr = {\n",
        "    'model':Categorical([SVR()]),\n",
        "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "    'model__gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "}"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ADy4dfjSVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model comparison\n",
        "opt = BayesSearchCV(\n",
        "    pipe,\n",
        "    [(svm_regr, 10), (rf_regr, 10), (lin_regr,1)], # (parameter space, # of evaluations)\n",
        "    cv=5,\n",
        "     n_iter=32,\n",
        "    random_state=0,\n",
        "    n_jobs=4, #parallelize\n",
        "    scoring='neg_mean_squared_error'\n",
        ")"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrlNiCtunT0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "0d2669f2-bdb4-44ea-f35a-cf649a46be6e"
      },
      "source": [
        "opt.fit(X_train,y_train)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BayesSearchCV(cv=5, error_score='raise',\n",
              "              estimator=Pipeline(memory=None,\n",
              "                                 steps=[('model',\n",
              "                                         SVR(C=1.0, cache_size=200, coef0=0.0,\n",
              "                                             degree=3, epsilon=0.1,\n",
              "                                             gamma='scale', kernel='rbf',\n",
              "                                             max_iter=-1, shrinking=True,\n",
              "                                             tol=0.001, verbose=False))],\n",
              "                                 verbose=False),\n",
              "              fit_params=None, iid=True, n_iter=32, n_jobs=4, n_points=1,\n",
              "              optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_stat...\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False),), prior=None),\n",
              "                               'model__n_estimators': Integer(low=10, high=100, prior='log-uniform', transform='identity')},\n",
              "                              10),\n",
              "                             ({'model': Categorical(categories=(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),), prior=None)},\n",
              "                              1)],\n",
              "              verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWpRDar0nivG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6288d741-d71e-4454-a226-498a793319ab"
      },
      "source": [
        "opt.best_score_\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0980889680984682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26BTpM7nsog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "72395ed2-5404-4ac8-81cb-0f94cf4fce05"
      },
      "source": [
        "opt.best_params_"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('model',\n",
              "              RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                                    max_samples=None, min_impurity_decrease=0.0,\n",
              "                                    min_impurity_split=None, min_samples_leaf=1,\n",
              "                                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                                    n_estimators=11, n_jobs=None, oob_score=False,\n",
              "                                    random_state=None, verbose=0, warm_start=False)),\n",
              "             ('model__n_estimators', 11)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    }
  ]
}